{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2: Network Shade Calculation\n",
    "## Shade-Optimized Pedestrian Routing to Transit\n",
    "\n",
    "**Author:** Kavana Raju  \n",
    "**Course:** MUSA 5500 - Geospatial Data Science with Python  \n",
    "**Date:** December 2025\n",
    "\n",
    "---\n",
    "\n",
    "This notebook calculates shade scores for all street segments:\n",
    "1. Calculate solar position for 8 temporal scenarios\n",
    "2. Model building shadows using geometric methods\n",
    "3. Extract tree canopy coverage (from LiDAR)\n",
    "4. Combine building + tree shade\n",
    "5. Assign shade scores to all network edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Imports successful\n"
     ]
    }
   ],
   "source": [
    "import osmnx as ox\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from shapely.geometry import Point, LineString, Polygon, box\n",
    "from shapely.ops import unary_union\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create output directories\n",
    "for d in ['outputs/figures', 'outputs/maps']:\n",
    "    Path(d).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"âœ“ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data from Notebook 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processed data from Notebook 1...\n",
      "\n",
      "âœ“ Network loaded: 23,486 edges, 7,343 nodes\n",
      "âœ“ Buildings loaded: 16,632 buildings\n",
      "  Using height column: height_ft (feet)\n",
      "  Mean height: 32.4 ft\n",
      "âœ“ Transit stops loaded: 60 stops\n",
      "âœ“ Study area loaded\n",
      "\n",
      "âœ“ All data loaded successfully\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading processed data from Notebook 1...\\n\")\n",
    "\n",
    "# Load street network\n",
    "edges_gdf = gpd.read_file('data/processed/network_edges.geojson')\n",
    "nodes_gdf = gpd.read_file('data/processed/network_nodes.geojson')\n",
    "print(f\"âœ“ Network loaded: {len(edges_gdf):,} edges, {len(nodes_gdf):,} nodes\")\n",
    "\n",
    "# Load buildings with heights\n",
    "buildings = gpd.read_file('data/processed/buildings_with_heights.geojson')\n",
    "print(f\"âœ“ Buildings loaded: {len(buildings):,} buildings\")\n",
    "\n",
    "# Check which height column exists\n",
    "if 'height_ft' in buildings.columns:\n",
    "    height_col = 'height_ft'\n",
    "    height_unit = 'feet'\n",
    "elif 'height_m' in buildings.columns:\n",
    "    height_col = 'height_m'\n",
    "    height_unit = 'meters'\n",
    "    # Convert to feet for consistency\n",
    "    buildings['height_ft'] = buildings['height_m'] * 3.28084\n",
    "    height_col = 'height_ft'\n",
    "    height_unit = 'feet (converted)'\n",
    "else:\n",
    "    raise ValueError(\"No height column found in buildings data!\")\n",
    "\n",
    "print(f\"  Using height column: {height_col} ({height_unit})\")\n",
    "print(f\"  Mean height: {buildings[height_col].mean():.1f} ft\")\n",
    "\n",
    "# Load SEPTA stops\n",
    "septa_stops = gpd.read_file('data/processed/septa_stops.geojson')\n",
    "print(f\"âœ“ Transit stops loaded: {len(septa_stops)} stops\")\n",
    "\n",
    "# Load study area\n",
    "study_area = gpd.read_file('data/processed/study_area.geojson')\n",
    "print(f\"âœ“ Study area loaded\")\n",
    "\n",
    "print(f\"\\nâœ“ All data loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Temporal Scenarios\n",
    "\n",
    "I analyzed shade at different times of day across seasons:\n",
    "- **Summer:** June 21 (longest day)\n",
    "- **Winter:** December 21 (shortest day)\n",
    "- **Spring:** March 21 (equinox)\n",
    "- **Fall:** September 21 (equinox)\n",
    "\n",
    "Times of day:\n",
    "- **Morning:** 9:00 AM\n",
    "- **Midday:** 12:00 PM  \n",
    "- **Evening:** 6:00 PM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal scenarios defined:\n",
      "  â€¢ summer_morning: June 21, 2024 at 09:00 AM\n",
      "  â€¢ summer_midday: June 21, 2024 at 12:00 PM\n",
      "  â€¢ summer_evening: June 21, 2024 at 06:00 PM\n",
      "  â€¢ winter_morning: December 21, 2024 at 09:00 AM\n",
      "  â€¢ winter_midday: December 21, 2024 at 12:00 PM\n",
      "  â€¢ winter_evening: December 21, 2024 at 06:00 PM\n",
      "  â€¢ spring_midday: March 21, 2024 at 12:00 PM\n",
      "  â€¢ fall_midday: September 21, 2024 at 12:00 PM\n",
      "\n",
      "Location: Philadelphia (39.9526Â°N, -75.1652Â°W)\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# Define scenarios\n",
    "scenarios = {\n",
    "    'summer_morning': datetime(2024, 6, 21, 9, 0),\n",
    "    'summer_midday': datetime(2024, 6, 21, 12, 0),\n",
    "    'summer_evening': datetime(2024, 6, 21, 18, 0),\n",
    "    'winter_morning': datetime(2024, 12, 21, 9, 0),\n",
    "    'winter_midday': datetime(2024, 12, 21, 12, 0),\n",
    "    'winter_evening': datetime(2024, 12, 21, 18, 0),\n",
    "    'spring_midday': datetime(2024, 3, 21, 12, 0),\n",
    "    'fall_midday': datetime(2024, 9, 21, 12, 0),\n",
    "}\n",
    "\n",
    "# Philadelphia location\n",
    "latitude = 39.9526\n",
    "longitude = -75.1652\n",
    "timezone = pytz.timezone('America/New_York')\n",
    "\n",
    "print(\"Temporal scenarios defined:\")\n",
    "for name, dt in scenarios.items():\n",
    "    print(f\"  â€¢ {name}: {dt.strftime('%B %d, %Y at %I:%M %p')}\")\n",
    "\n",
    "print(f\"\\nLocation: Philadelphia ({latitude:.4f}Â°N, {longitude:.4f}Â°W)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculate Solar Position for Each Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating solar position for each scenario...\n",
      "\n",
      "summer_morning       - Altitude:  36.90Â° | Azimuth:  88.85Â°\n",
      "summer_midday        - Altitude:  68.86Â° | Azimuth: 136.67Â°\n",
      "summer_evening       - Altitude:  26.48Â° | Azimuth: 279.37Â°\n",
      "winter_morning       - Altitude:  14.19Â° | Azimuth: 138.24Â°\n",
      "winter_midday        - Altitude:  26.64Â° | Azimuth: 180.24Â°\n",
      "winter_evening       - Altitude: -14.95Â° | Azimuth: 251.74Â°\n",
      "spring_midday        - Altitude:  47.76Â° | Azimuth: 154.38Â°\n",
      "fall_midday          - Altitude:  48.56Â° | Azimuth: 159.55Â°\n",
      "\n",
      "âœ“ Solar positions calculated and saved\n"
     ]
    }
   ],
   "source": [
    "import pvlib\n",
    "\n",
    "print(\"Calculating solar position for each scenario...\\n\")\n",
    "\n",
    "solar_positions = {}\n",
    "\n",
    "for scenario_name, dt in scenarios.items():\n",
    "    # Localize datetime\n",
    "    dt_local = timezone.localize(dt)\n",
    "    \n",
    "    # Calculate solar position\n",
    "    solar_pos = pvlib.solarposition.get_solarposition(\n",
    "        dt_local,\n",
    "        latitude,\n",
    "        longitude\n",
    "    )\n",
    "    \n",
    "    altitude = solar_pos['apparent_elevation'].values[0]\n",
    "    azimuth = solar_pos['azimuth'].values[0]\n",
    "    \n",
    "    solar_positions[scenario_name] = {\n",
    "        'altitude': altitude,\n",
    "        'azimuth': azimuth,\n",
    "        'datetime': dt\n",
    "    }\n",
    "    \n",
    "    print(f\"{scenario_name:20s} - Altitude: {altitude:6.2f}Â° | Azimuth: {azimuth:6.2f}Â°\")\n",
    "\n",
    "# Save solar positions\n",
    "solar_df = pd.DataFrame(solar_positions).T\n",
    "solar_df.to_csv('data/processed/solar_positions.csv')\n",
    "print(f\"\\nâœ“ Solar positions calculated and saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate Building Shadows for Each Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data projected to EPSG:2272\n",
      "  Buildings: 16,632\n",
      "  Street edges: 23,486\n"
     ]
    }
   ],
   "source": [
    "# Project data to PA State Plane (feet) for shadow calculations\n",
    "CRS_PROJECTED = 'EPSG:2272'\n",
    "\n",
    "buildings_proj = buildings.to_crs(CRS_PROJECTED)\n",
    "edges_proj = edges_gdf.to_crs(CRS_PROJECTED)\n",
    "\n",
    "print(f\"Data projected to {CRS_PROJECTED}\")\n",
    "print(f\"  Buildings: {len(buildings_proj):,}\")\n",
    "print(f\"  Street edges: {len(edges_proj):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Shadow calculation function defined\n"
     ]
    }
   ],
   "source": [
    "def calculate_building_shadow(building_geom, height_ft, altitude_deg, azimuth_deg):\n",
    "    \"\"\"\n",
    "    Calculate shadow polygon for a building.\n",
    "    \n",
    "    Parameters:\n",
    "    - building_geom: Building footprint geometry\n",
    "    - height_ft: Building height in feet\n",
    "    - altitude_deg: Solar altitude angle in degrees\n",
    "    - azimuth_deg: Solar azimuth angle in degrees (0=North, 90=East)\n",
    "    \n",
    "    Returns:\n",
    "    - Shadow polygon\n",
    "    \"\"\"\n",
    "    # If sun is below horizon or building has no height, no shadow\n",
    "    if altitude_deg <= 0 or height_ft <= 0:\n",
    "        return None\n",
    "    \n",
    "    # Calculate shadow length\n",
    "    altitude_rad = np.radians(altitude_deg)\n",
    "    shadow_length = height_ft / np.tan(altitude_rad)\n",
    "    \n",
    "    # Calculate shadow direction (opposite of sun)\n",
    "    shadow_azimuth = (azimuth_deg + 180) % 360\n",
    "    shadow_azimuth_rad = np.radians(shadow_azimuth)\n",
    "    \n",
    "    # Calculate shadow offset\n",
    "    dx = shadow_length * np.sin(shadow_azimuth_rad)\n",
    "    dy = shadow_length * np.cos(shadow_azimuth_rad)\n",
    "    \n",
    "    # Create shadow polygon by translating building footprint\n",
    "    try:\n",
    "        from shapely.affinity import translate\n",
    "        shadow = translate(building_geom, xoff=dx, yoff=dy)\n",
    "        \n",
    "        # Union with building footprint for full shadow\n",
    "        full_shadow = unary_union([building_geom, shadow])\n",
    "        \n",
    "        return full_shadow.convex_hull if full_shadow.is_valid else None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "print(\"âœ“ Shadow calculation function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating building shadows for all scenarios...\n",
      "\n",
      "This will take 30-45 minutes for ~16k buildings Ã— 8 scenarios\n",
      "Please be patient...\n",
      "\n",
      "Processing: summer_morning...\n",
      "  2,000 / 16,632 buildings processed\n",
      "  4,000 / 16,632 buildings processed\n",
      "  6,000 / 16,632 buildings processed\n",
      "  8,000 / 16,632 buildings processed\n",
      "  10,000 / 16,632 buildings processed\n",
      "  12,000 / 16,632 buildings processed\n",
      "  14,000 / 16,632 buildings processed\n",
      "  16,000 / 16,632 buildings processed\n",
      "  âœ“ 16,632 shadows calculated\n",
      "\n",
      "Processing: summer_midday...\n",
      "  2,000 / 16,632 buildings processed\n",
      "  4,000 / 16,632 buildings processed\n",
      "  6,000 / 16,632 buildings processed\n",
      "  8,000 / 16,632 buildings processed\n",
      "  10,000 / 16,632 buildings processed\n",
      "  12,000 / 16,632 buildings processed\n",
      "  14,000 / 16,632 buildings processed\n",
      "  16,000 / 16,632 buildings processed\n",
      "  âœ“ 16,632 shadows calculated\n",
      "\n",
      "Processing: summer_evening...\n",
      "  2,000 / 16,632 buildings processed\n",
      "  4,000 / 16,632 buildings processed\n",
      "  6,000 / 16,632 buildings processed\n",
      "  8,000 / 16,632 buildings processed\n",
      "  10,000 / 16,632 buildings processed\n",
      "  12,000 / 16,632 buildings processed\n",
      "  14,000 / 16,632 buildings processed\n",
      "  16,000 / 16,632 buildings processed\n",
      "  âœ“ 16,632 shadows calculated\n",
      "\n",
      "Processing: winter_morning...\n",
      "  2,000 / 16,632 buildings processed\n",
      "  4,000 / 16,632 buildings processed\n",
      "  6,000 / 16,632 buildings processed\n",
      "  8,000 / 16,632 buildings processed\n",
      "  10,000 / 16,632 buildings processed\n",
      "  12,000 / 16,632 buildings processed\n",
      "  14,000 / 16,632 buildings processed\n",
      "  16,000 / 16,632 buildings processed\n",
      "  âœ“ 16,632 shadows calculated\n",
      "\n",
      "Processing: winter_midday...\n",
      "  2,000 / 16,632 buildings processed\n",
      "  4,000 / 16,632 buildings processed\n",
      "  6,000 / 16,632 buildings processed\n",
      "  8,000 / 16,632 buildings processed\n",
      "  10,000 / 16,632 buildings processed\n",
      "  12,000 / 16,632 buildings processed\n",
      "  14,000 / 16,632 buildings processed\n",
      "  16,000 / 16,632 buildings processed\n",
      "  âœ“ 16,632 shadows calculated\n",
      "\n",
      "Processing: winter_evening...\n",
      "  2,000 / 16,632 buildings processed\n",
      "  4,000 / 16,632 buildings processed\n",
      "  6,000 / 16,632 buildings processed\n",
      "  8,000 / 16,632 buildings processed\n",
      "  10,000 / 16,632 buildings processed\n",
      "  12,000 / 16,632 buildings processed\n",
      "  14,000 / 16,632 buildings processed\n",
      "  16,000 / 16,632 buildings processed\n",
      "  âœ“ 0 shadows calculated\n",
      "\n",
      "Processing: spring_midday...\n",
      "  2,000 / 16,632 buildings processed\n",
      "  4,000 / 16,632 buildings processed\n",
      "  6,000 / 16,632 buildings processed\n",
      "  8,000 / 16,632 buildings processed\n",
      "  10,000 / 16,632 buildings processed\n",
      "  12,000 / 16,632 buildings processed\n",
      "  14,000 / 16,632 buildings processed\n",
      "  16,000 / 16,632 buildings processed\n",
      "  âœ“ 16,632 shadows calculated\n",
      "\n",
      "Processing: fall_midday...\n",
      "  2,000 / 16,632 buildings processed\n",
      "  4,000 / 16,632 buildings processed\n",
      "  6,000 / 16,632 buildings processed\n",
      "  8,000 / 16,632 buildings processed\n",
      "  10,000 / 16,632 buildings processed\n",
      "  12,000 / 16,632 buildings processed\n",
      "  14,000 / 16,632 buildings processed\n",
      "  16,000 / 16,632 buildings processed\n",
      "  âœ“ 16,632 shadows calculated\n",
      "\n",
      "âœ“ All building shadows calculated\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCalculating building shadows for all scenarios...\\n\")\n",
    "print(\"This will take 30-45 minutes for ~16k buildings Ã— 8 scenarios\")\n",
    "print(\"Please be patient...\\n\")\n",
    "\n",
    "# Store shadow geometries for each scenario\n",
    "building_shadows = {}\n",
    "\n",
    "for scenario_name, solar_data in solar_positions.items():\n",
    "    print(f\"Processing: {scenario_name}...\")\n",
    "    \n",
    "    altitude = solar_data['altitude']\n",
    "    azimuth = solar_data['azimuth']\n",
    "    \n",
    "    shadows = []\n",
    "    \n",
    "    for idx, building in buildings_proj.iterrows():\n",
    "        shadow = calculate_building_shadow(\n",
    "            building.geometry,\n",
    "            building[height_col],\n",
    "            altitude,\n",
    "            azimuth\n",
    "        )\n",
    "        \n",
    "        if shadow is not None:\n",
    "            shadows.append(shadow)\n",
    "        \n",
    "        # Progress indicator\n",
    "        if (idx + 1) % 2000 == 0:\n",
    "            print(f\"  {idx+1:,} / {len(buildings_proj):,} buildings processed\")\n",
    "    \n",
    "    # Create GeoDataFrame of shadows\n",
    "    shadows_gdf = gpd.GeoDataFrame(\n",
    "        geometry=shadows,\n",
    "        crs=CRS_PROJECTED\n",
    "    )\n",
    "    \n",
    "    building_shadows[scenario_name] = shadows_gdf\n",
    "    \n",
    "    print(f\"  âœ“ {len(shadows):,} shadows calculated\\n\")\n",
    "\n",
    "print(\"âœ“ All building shadows calculated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Extract Tree Canopy Coverage\n",
    "\n",
    "Using LiDAR heights for shadows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "OPTIMIZED TREE SHADOW CALCULATION (EDGE-BY-EDGE APPROACH)\n",
      "======================================================================\n",
      "\n",
      "âœ“ LiDAR tree HEIGHT raster found\n",
      "  Using optimized edge-by-edge approach (processes shadows on-the-fly)\n",
      "  Time estimate: ~2 hours total for all 8 scenarios\n",
      "\n",
      "Tree height raster loaded:\n",
      "  Shape: (2563, 4741)\n",
      "  Mean height: 116.4 ft\n",
      "  Max height: 208.2 ft\n",
      "  Pixel size: 3.0 ft\n",
      "  CRS: EPSG:2272\n",
      "\n",
      "âœ“ Step 1 complete - raster loaded and ready\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 1: LOAD TREE HEIGHT RASTER\n",
    "# ============================================================================\n",
    "\n",
    "import rasterio\n",
    "from rasterio.mask import mask as raster_mask\n",
    "from shapely.geometry import box, mapping\n",
    "from shapely.ops import unary_union\n",
    "from shapely.affinity import translate\n",
    "import time\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"OPTIMIZED TREE SHADOW CALCULATION (EDGE-BY-EDGE APPROACH)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "tree_height_raster_path = Path('data/processed/tree_heights_from_lidar.tif')\n",
    "\n",
    "if not tree_height_raster_path.exists():\n",
    "    print(\"\\nâš  Tree height raster not found!\")\n",
    "    raise FileNotFoundError(\"Need tree_heights_from_lidar.tif\")\n",
    "\n",
    "print(\"\\nâœ“ LiDAR tree HEIGHT raster found\")\n",
    "print(\"  Using optimized edge-by-edge approach (processes shadows on-the-fly)\")\n",
    "print(\"  Time estimate: ~2 hours total for all 8 scenarios\\n\")\n",
    "\n",
    "# Load tree height raster ONCE\n",
    "with rasterio.open(tree_height_raster_path) as src:\n",
    "    tree_height_data = src.read(1)\n",
    "    tree_transform = src.transform\n",
    "    tree_crs = src.crs\n",
    "    pixel_size = tree_transform[0]\n",
    "\n",
    "print(f\"Tree height raster loaded:\")\n",
    "print(f\"  Shape: {tree_height_data.shape}\")\n",
    "print(f\"  Mean height: {tree_height_data[tree_height_data > 0].mean():.1f} ft\")\n",
    "print(f\"  Max height: {tree_height_data.max():.1f} ft\")\n",
    "print(f\"  Pixel size: {pixel_size:.1f} ft\")\n",
    "print(f\"  CRS: {tree_crs}\")\n",
    "\n",
    "# Open raster for reading (keep open during processing)\n",
    "tree_raster = rasterio.open(tree_height_raster_path)\n",
    "\n",
    "print(\"\\nâœ“ Step 1 complete - raster loaded and ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "INITIALIZING PROGRESS TRACKING\n",
      "======================================================================\n",
      "\n",
      "âœ“ Starting fresh (no previous checkpoint)\n",
      "\n",
      "Scenarios to process: 8\n",
      "Scenarios remaining: 8\n",
      "\n",
      "âœ“ Step 2 complete - tracking initialized\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 2: INITIALIZE PROGRESS TRACKING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INITIALIZING PROGRESS TRACKING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create dictionary to track completed scenarios\n",
    "completed_scenarios = {}\n",
    "scenario_times = {}\n",
    "\n",
    "# Create backup directory\n",
    "import os\n",
    "os.makedirs('data/processed/checkpoints', exist_ok=True)\n",
    "\n",
    "# Check if we have any previous progress\n",
    "checkpoint_file = Path('data/processed/checkpoints/shade_progress.pkl')\n",
    "if checkpoint_file.exists():\n",
    "    import pickle\n",
    "    with open(checkpoint_file, 'rb') as f:\n",
    "        checkpoint_data = pickle.load(f)\n",
    "        completed_scenarios = checkpoint_data.get('completed', {})\n",
    "        print(f\"\\nâœ“ Found checkpoint with {len(completed_scenarios)} completed scenarios\")\n",
    "        for scenario in completed_scenarios.keys():\n",
    "            print(f\"  - {scenario}\")\n",
    "else:\n",
    "    print(\"\\nâœ“ Starting fresh (no previous checkpoint)\")\n",
    "\n",
    "print(f\"\\nScenarios to process: {len(scenarios)}\")\n",
    "print(f\"Scenarios remaining: {len(scenarios) - len(completed_scenarios)}\")\n",
    "\n",
    "print(\"\\nâœ“ Step 2 complete - tracking initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PROCESSING SCENARIOS (WITH AUTO-SAVE AFTER EACH)\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "PROCESSING: summer_morning\n",
      "======================================================================\n",
      "  Sun altitude: 36.9Â° | Shadow direction: 268.8Â°\n",
      "  Estimated time: 15-20 minutes\n",
      "  Processing 23,486 edges...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 3: PROCESS SCENARIOS ONE AT A TIME\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PROCESSING SCENARIOS (WITH AUTO-SAVE AFTER EACH)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for scenario_name, solar_data in solar_positions.items():\n",
    "    \n",
    "    # Skip if already completed\n",
    "    if scenario_name in completed_scenarios:\n",
    "        print(f\"\\nâœ“ {scenario_name} - ALREADY COMPLETED (skipping)\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"PROCESSING: {scenario_name}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    scenario_start_time = time.time()\n",
    "    \n",
    "    altitude = solar_data['altitude']\n",
    "    azimuth = solar_data['azimuth']\n",
    "    \n",
    "    # Skip if sun is below horizon\n",
    "    if altitude <= 0:\n",
    "        print(f\"  âš  Sun below horizon, skipping\")\n",
    "        \n",
    "        edges_proj[f'building_shadow_{scenario_name}'] = [0] * len(edges_proj)\n",
    "        edges_proj[f'tree_shadow_{scenario_name}'] = [0] * len(edges_proj)\n",
    "        edges_proj[f'shade_{scenario_name}'] = [0] * len(edges_proj)\n",
    "        \n",
    "        completed_scenarios[scenario_name] = 'below_horizon'\n",
    "        scenario_times[scenario_name] = 0\n",
    "        \n",
    "        # Save checkpoint\n",
    "        import pickle\n",
    "        with open('data/processed/checkpoints/shade_progress.pkl', 'wb') as f:\n",
    "            pickle.dump({\n",
    "                'completed': completed_scenarios,\n",
    "                'times': scenario_times\n",
    "            }, f)\n",
    "        \n",
    "        print(f\"  âœ“ Checkpoint saved\\n\")\n",
    "        continue\n",
    "    \n",
    "    # Calculate shadow parameters\n",
    "    altitude_rad = np.radians(altitude)\n",
    "    shadow_azimuth = (azimuth + 180) % 360\n",
    "    shadow_azimuth_rad = np.radians(shadow_azimuth)\n",
    "    \n",
    "    print(f\"  Sun altitude: {altitude:.1f}Â° | Shadow direction: {shadow_azimuth:.1f}Â°\")\n",
    "    print(f\"  Estimated time: 15-20 minutes\")\n",
    "    print(f\"  Processing {len(edges_proj):,} edges...\\n\")\n",
    "    \n",
    "    # Get building shadows for this scenario\n",
    "    building_shadows_gdf = building_shadows[scenario_name]\n",
    "    building_shadow_union = unary_union(building_shadows_gdf.geometry)\n",
    "    \n",
    "    building_shade_scores = []\n",
    "    tree_shade_scores = []\n",
    "    combined_shade_scores = []\n",
    "    \n",
    "    # Process each edge\n",
    "    for idx, edge in edges_proj.iterrows():\n",
    "        try:\n",
    "            edge_geom = edge.geometry\n",
    "            edge_length = edge_geom.length\n",
    "            \n",
    "            # ============================================================\n",
    "            # BUILDING SHADOW COVERAGE\n",
    "            # ============================================================\n",
    "            if building_shadow_union.intersects(edge_geom):\n",
    "                building_intersection = building_shadow_union.intersection(edge_geom)\n",
    "                building_coverage = building_intersection.length / edge_length\n",
    "            else:\n",
    "                building_coverage = 0\n",
    "            building_coverage = min(building_coverage, 1.0)\n",
    "            \n",
    "            # ============================================================\n",
    "            # TREE SHADOW COVERAGE (ON-THE-FLY CALCULATION)\n",
    "            # ============================================================\n",
    "            \n",
    "            # Create buffer around edge to capture nearby trees\n",
    "            # Buffer size based on potential shadow length\n",
    "            max_shadow_length = 200 / np.tan(max(altitude_rad, 0.1))\n",
    "            buffer_dist = min(max_shadow_length, 500)  # Cap at 500ft\n",
    "            \n",
    "            edge_buffer = edge_geom.buffer(buffer_dist)\n",
    "            \n",
    "            # Extract tree heights in buffered area\n",
    "            try:\n",
    "                geom = [mapping(edge_buffer)]\n",
    "                out_image, out_transform = raster_mask(\n",
    "                    tree_raster,\n",
    "                    geom,\n",
    "                    crop=True,\n",
    "                    all_touched=True,\n",
    "                    nodata=0\n",
    "                )\n",
    "                \n",
    "                tree_heights_subset = out_image[0]\n",
    "                \n",
    "                # Find tree pixels (height > 0)\n",
    "                tree_pixels = np.argwhere(tree_heights_subset > 0)\n",
    "                \n",
    "                if len(tree_pixels) > 0:\n",
    "                    # Create shadow polygons for tree pixels in this area\n",
    "                    local_tree_shadows = []\n",
    "                    \n",
    "                    # Sample pixels if too many (for performance)\n",
    "                    if len(tree_pixels) > 2000:\n",
    "                        indices = np.random.choice(len(tree_pixels), 2000, replace=False)\n",
    "                        tree_pixels = tree_pixels[indices]\n",
    "                    \n",
    "                    for pixel_row, pixel_col in tree_pixels:\n",
    "                        tree_height = tree_heights_subset[pixel_row, pixel_col]\n",
    "                        \n",
    "                        if tree_height <= 0:\n",
    "                            continue\n",
    "                        \n",
    "                        # Get pixel coordinates\n",
    "                        px, py = rasterio.transform.xy(\n",
    "                            out_transform,\n",
    "                            pixel_row,\n",
    "                            pixel_col\n",
    "                        )\n",
    "                        \n",
    "                        # Create pixel box\n",
    "                        pixel_box = box(\n",
    "                            px - pixel_size/2,\n",
    "                            py - pixel_size/2,\n",
    "                            px + pixel_size/2,\n",
    "                            py + pixel_size/2\n",
    "                        )\n",
    "                        \n",
    "                        # Calculate shadow\n",
    "                        shadow_length = tree_height / np.tan(altitude_rad)\n",
    "                        dx = shadow_length * np.sin(shadow_azimuth_rad)\n",
    "                        dy = shadow_length * np.cos(shadow_azimuth_rad)\n",
    "                        \n",
    "                        shadow = translate(pixel_box, xoff=dx, yoff=dy)\n",
    "                        \n",
    "                        try:\n",
    "                            full_shadow = unary_union([pixel_box, shadow])\n",
    "                            if full_shadow.is_valid:\n",
    "                                local_tree_shadows.append(full_shadow)\n",
    "                        except:\n",
    "                            pass\n",
    "                    \n",
    "                    # Union local tree shadows\n",
    "                    if len(local_tree_shadows) > 0:\n",
    "                        try:\n",
    "                            local_tree_shadow_union = unary_union(local_tree_shadows)\n",
    "                            \n",
    "                            # Calculate intersection with edge\n",
    "                            if local_tree_shadow_union.intersects(edge_geom):\n",
    "                                tree_intersection = local_tree_shadow_union.intersection(edge_geom)\n",
    "                                tree_coverage = tree_intersection.length / edge_length\n",
    "                            else:\n",
    "                                tree_coverage = 0\n",
    "                        except:\n",
    "                            tree_coverage = 0\n",
    "                    else:\n",
    "                        tree_coverage = 0\n",
    "                else:\n",
    "                    tree_coverage = 0\n",
    "            \n",
    "            except Exception as e:\n",
    "                tree_coverage = 0\n",
    "            \n",
    "            tree_coverage = min(tree_coverage, 1.0)\n",
    "            \n",
    "            # ============================================================\n",
    "            # COMBINED SHADE\n",
    "            # ============================================================\n",
    "            combined_shade = (0.6 * building_coverage) + (0.4 * tree_coverage)\n",
    "            \n",
    "            building_shade_scores.append(building_coverage)\n",
    "            tree_shade_scores.append(tree_coverage)\n",
    "            combined_shade_scores.append(combined_shade)\n",
    "            \n",
    "        except Exception as e:\n",
    "            building_shade_scores.append(0)\n",
    "            tree_shade_scores.append(0)\n",
    "            combined_shade_scores.append(0)\n",
    "        \n",
    "        # Progress indicator\n",
    "        if (idx + 1) % 500 == 0:\n",
    "            elapsed = time.time() - scenario_start_time\n",
    "            rate = (idx + 1) / elapsed if elapsed > 0 else 0\n",
    "            remaining = (len(edges_proj) - idx - 1) / rate if rate > 0 else 0\n",
    "            print(f\"    {idx+1:,} / {len(edges_proj):,} edges ({100*(idx+1)/len(edges_proj):.1f}%) | \"\n",
    "                  f\"ETA: {remaining/60:.1f} min\")\n",
    "    \n",
    "    # Store all shade columns for this scenario\n",
    "    edges_proj[f'building_shadow_{scenario_name}'] = building_shade_scores\n",
    "    edges_proj[f'tree_shadow_{scenario_name}'] = tree_shade_scores\n",
    "    edges_proj[f'shade_{scenario_name}'] = combined_shade_scores\n",
    "    \n",
    "    # Calculate statistics\n",
    "    mean_building = np.mean(building_shade_scores)\n",
    "    mean_tree = np.mean(tree_shade_scores)\n",
    "    mean_combined = np.mean(combined_shade_scores)\n",
    "    \n",
    "    scenario_elapsed = time.time() - scenario_start_time\n",
    "    scenario_times[scenario_name] = scenario_elapsed\n",
    "    \n",
    "    print(f\"\\n  âœ“ Scenario complete in {scenario_elapsed/60:.1f} minutes\")\n",
    "    print(f\"  Building: {mean_building:.3f} | Tree: {mean_tree:.3f} | Combined: {mean_combined:.3f}\")\n",
    "    print(f\"  Max combined: {max(combined_shade_scores):.3f}\")\n",
    "    print(f\"  Segments >50%: {sum(1 for s in combined_shade_scores if s > 0.5):,}\")\n",
    "    \n",
    "    # Mark as completed\n",
    "    completed_scenarios[scenario_name] = 'completed'\n",
    "    \n",
    "    # ========================================================================\n",
    "    # SAVE CHECKPOINT AFTER EACH SCENARIO\n",
    "    # ========================================================================\n",
    "    print(f\"\\n  ðŸ’¾ SAVING CHECKPOINT...\")\n",
    "    \n",
    "    import pickle\n",
    "    \n",
    "    # Save progress tracker\n",
    "    with open('data/processed/checkpoints/shade_progress.pkl', 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'completed': completed_scenarios,\n",
    "            'times': scenario_times\n",
    "        }, f)\n",
    "    \n",
    "    # Save edges with current progress\n",
    "    edges_proj.to_file(\n",
    "        f'data/processed/checkpoints/edges_checkpoint_{len(completed_scenarios)}.geojson',\n",
    "        driver='GeoJSON'\n",
    "    )\n",
    "    \n",
    "    print(f\"  âœ“ Checkpoint saved ({len(completed_scenarios)}/{len(scenarios)} scenarios complete)\")\n",
    "    print(f\"  âœ“ Progress saved to: checkpoints/edges_checkpoint_{len(completed_scenarios)}.geojson\")\n",
    "    \n",
    "    # Estimate remaining time\n",
    "    if len(scenario_times) > 0:\n",
    "        avg_time = np.mean(list(scenario_times.values()))\n",
    "        remaining_scenarios = len(scenarios) - len(completed_scenarios)\n",
    "        estimated_remaining = (avg_time * remaining_scenarios) / 60\n",
    "        print(f\"  ðŸ“Š Estimated remaining time: {estimated_remaining:.1f} minutes\\n\")\n",
    "\n",
    "# Close raster\n",
    "tree_raster.close()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ“ ALL SCENARIOS COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nTotal scenarios processed: {len(completed_scenarios)}\")\n",
    "print(f\"Total time: {sum(scenario_times.values())/60:.1f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 4: FINAL SAVE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL SAVE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Convert to WGS84\n",
    "print(\"\\nConverting to WGS84...\")\n",
    "edges_final = edges_proj.to_crs('EPSG:4326')\n",
    "\n",
    "# Save final network\n",
    "output_path = 'data/processed/network_edges_with_shade.geojson'\n",
    "print(f\"Saving to: {output_path}\")\n",
    "edges_final.to_file(output_path, driver='GeoJSON')\n",
    "\n",
    "# Get file size\n",
    "import os\n",
    "file_size_mb = os.path.getsize(output_path) / (1024 * 1024)\n",
    "\n",
    "print(f\"\\nâœ“ Network saved!\")\n",
    "print(f\"  File: {output_path}\")\n",
    "print(f\"  Size: {file_size_mb:.1f} MB\")\n",
    "print(f\"  Columns: {len(edges_final.columns)}\")\n",
    "\n",
    "# Count shade columns\n",
    "shade_cols = [c for c in edges_final.columns if c.startswith('shade_') and 'shadow' not in c]\n",
    "print(f\"  Shade scenarios: {len(shade_cols)}\")\n",
    "\n",
    "# Clean up checkpoints\n",
    "print(\"\\nðŸ’¾ Cleaning up checkpoints...\")\n",
    "import shutil\n",
    "if Path('data/processed/checkpoints').exists():\n",
    "    # Keep progress file, remove edge checkpoints\n",
    "    for f in Path('data/processed/checkpoints').glob('edges_checkpoint_*.geojson'):\n",
    "        f.unlink()\n",
    "        print(f\"  Removed: {f.name}\")\n",
    "\n",
    "print(\"\\nâœ“ Step 4 complete - final save done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 5: SUMMARY STATISTICS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SHADE ANALYSIS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nNetwork Statistics:\")\n",
    "print(f\"  Total edges: {len(edges_final):,}\")\n",
    "print(f\"  Total length: {edges_final.geometry.length.sum()/5280:.1f} miles\")\n",
    "\n",
    "print(f\"\\nShade Score Statistics:\")\n",
    "print(f\"{'Scenario':<20} {'Mean':<8} {'Min':<8} {'Max':<8} {'High Shade (>0.5)'}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for col in sorted([c for c in edges_final.columns if c.startswith('shade_') and 'shadow' not in c]):\n",
    "    scenario = col.replace('shade_', '')\n",
    "    values = edges_final[col].values\n",
    "    mean_val = np.mean(values)\n",
    "    min_val = np.min(values)\n",
    "    max_val = np.max(values)\n",
    "    high_count = np.sum(values > 0.5)\n",
    "    high_pct = 100 * high_count / len(values)\n",
    "    \n",
    "    print(f\"{scenario:<20} {mean_val:.3f}    {min_val:.3f}    {max_val:.3f}    \"\n",
    "          f\"{high_count:,} ({high_pct:.1f}%)\")\n",
    "\n",
    "# Processing time summary\n",
    "print(f\"\\nProcessing Time by Scenario:\")\n",
    "import pickle\n",
    "with open('data/processed/checkpoints/shade_progress.pkl', 'rb') as f:\n",
    "    checkpoint = pickle.load(f)\n",
    "    times = checkpoint['times']\n",
    "\n",
    "for scenario, elapsed in sorted(times.items()):\n",
    "    print(f\"  {scenario:<20} {elapsed/60:.1f} min\")\n",
    "\n",
    "print(f\"\\nTotal computation time: {sum(times.values())/60:.1f} minutes\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"NOTEBOOK 2 COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nâœ“ Building shadows from LiDAR heights (99.7% coverage)\")\n",
    "print(\"âœ“ Tree shadows from LiDAR heights (geometric projection)\")\n",
    "print(\"âœ“ Combined shade scores for all scenarios\")\n",
    "print(\"âœ“ Network ready for routing analysis\")\n",
    "\n",
    "print(\"\\nðŸ“Š Ready for Notebook 3!\")\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SAVE NETWORK WITH SHADE SCORES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SAVING NETWORK WITH SHADE SCORES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Convert back to WGS84 for saving\n",
    "print(\"\\nConverting to WGS84 for output...\")\n",
    "edges_final = edges_proj.to_crs('EPSG:4326')\n",
    "\n",
    "# Save complete network with all shade scores\n",
    "output_path = 'data/processed/network_edges_with_shade.geojson'\n",
    "print(f\"Saving network to: {output_path}\")\n",
    "edges_final.to_file(output_path, driver='GeoJSON')\n",
    "\n",
    "print(\"\\nâœ“ Network with shade scores saved!\")\n",
    "print(f\"  File: {output_path}\")\n",
    "print(f\"\\n  Total columns: {len(edges_final.columns)}\")\n",
    "\n",
    "# Count shade-related columns\n",
    "building_shade_cols = [c for c in edges_final.columns if 'building_shadow_' in c]\n",
    "tree_shade_cols = [c for c in edges_final.columns if 'tree_shadow_' in c]\n",
    "combined_shade_cols = [c for c in edges_final.columns if c.startswith('shade_') and not 'shadow' in c]\n",
    "\n",
    "print(f\"  Building shadow columns: {len(building_shade_cols)}\")\n",
    "print(f\"  Tree shadow columns:     {len(tree_shade_cols)}\")\n",
    "print(f\"  Combined shade columns:  {len(combined_shade_cols)}\")\n",
    "\n",
    "# Show scenario coverage\n",
    "print(f\"\\n  Scenarios saved: {len(combined_shade_cols)}\")\n",
    "if len(combined_shade_cols) > 0:\n",
    "    scenario_names = [c.replace('shade_', '') for c in combined_shade_cols]\n",
    "    for i, name in enumerate(scenario_names, 1):\n",
    "        print(f\"    {i}. {name}\")\n",
    "\n",
    "# File size info\n",
    "import os\n",
    "file_size_mb = os.path.getsize(output_path) / (1024 * 1024)\n",
    "print(f\"\\n  File size: {file_size_mb:.1f} MB\")\n",
    "\n",
    "# ============================================================================\n",
    "# SUMMARY STATISTICS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SHADE ANALYSIS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nNetwork Statistics:\")\n",
    "print(f\"  Total edges: {len(edges_final):,}\")\n",
    "print(f\"  Total length: {edges_final.geometry.length.sum()/5280:.1f} miles\")\n",
    "\n",
    "print(f\"\\nShade Score Statistics Across All Scenarios:\")\n",
    "print(f\"{'Scenario':<20} {'Mean':<8} {'Min':<8} {'Max':<8} {'High Shade (>0.5)'}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for col in combined_shade_cols:\n",
    "    scenario = col.replace('shade_', '')\n",
    "    values = edges_final[col].values\n",
    "    mean_val = np.mean(values)\n",
    "    min_val = np.min(values)\n",
    "    max_val = np.max(values)\n",
    "    high_shade_count = np.sum(values > 0.5)\n",
    "    high_shade_pct = 100 * high_shade_count / len(values)\n",
    "    \n",
    "    print(f\"{scenario:<20} {mean_val:.3f}    {min_val:.3f}    {max_val:.3f}    \"\n",
    "          f\"{high_shade_count:,} ({high_shade_pct:.1f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# COMPLETION MESSAGE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"NOTEBOOK 2 COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nâœ“ Building shadows calculated from LiDAR heights (99.7% coverage)\")\n",
    "print(\"âœ“ Tree shadows calculated from LiDAR heights (geometric projection)\")\n",
    "print(\"âœ“ Combined shade scores computed for all scenarios\")\n",
    "print(\"âœ“ Network saved with all shade attributes\")\n",
    "\n",
    "print(\"\\nðŸ“Š Ready for Notebook 3: Routing Analysis\")\n",
    "print(\"   The network is now ready for shade-weighted pathfinding!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
