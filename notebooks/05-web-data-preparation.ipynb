{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 5: Web Data Preparation\n",
    "## Shade-Optimized Pedestrian Routing to Transit\n",
    "\n",
    "**Author:** Kavana Raju  \n",
    "**Course:** MUSA 5500 - Geospatial Data Science with Python  \n",
    "**Date:** December 2025\n",
    "\n",
    "---\n",
    "\n",
    "This notebook prepares data for the interactive web application:\n",
    "1. Load processed network data\n",
    "2. Convert to web-friendly JSON format\n",
    "3. Optimize for browser loading\n",
    "4. Create data files for React app\n",
    "5. Validate output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading processed data from previous notebooks...\\n\")\n",
    "\n",
    "# Load network with shade scores (from Notebook 2)\n",
    "edges = gpd.read_file('data/processed/network_edges_with_shade.geojson')\n",
    "print(f\"✓ Edges loaded: {len(edges):,}\")\n",
    "\n",
    "# Load nodes\n",
    "nodes = gpd.read_file('data/processed/network_nodes.geojson')\n",
    "print(f\"✓ Nodes loaded: {len(nodes):,}\")\n",
    "\n",
    "# Load SEPTA stops\n",
    "septa = gpd.read_file('data/processed/septa_stops.geojson')\n",
    "print(f\"✓ SEPTA stops loaded: {len(septa)}\")\n",
    "\n",
    "# Load study area\n",
    "study_area = gpd.read_file('data/processed/study_area.geojson')\n",
    "print(f\"✓ Study area loaded\")\n",
    "\n",
    "# Get available shade scenarios\n",
    "shade_cols = [c for c in edges.columns if c.startswith('shade_')]\n",
    "scenarios = [c.replace('shade_', '') for c in shade_cols]\n",
    "\n",
    "print(f\"\\n✓ Found {len(scenarios)} temporal scenarios:\")\n",
    "for s in scenarios:\n",
    "    print(f\"  • {s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Convert to WGS84 (Web Standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Converting to WGS84 (EPSG:4326) for web compatibility...\\n\")\n",
    "\n",
    "# Convert all data to WGS84\n",
    "edges_web = edges.to_crs('EPSG:4326')\n",
    "nodes_web = nodes.to_crs('EPSG:4326')\n",
    "septa_web = septa.to_crs('EPSG:4326')\n",
    "study_area_web = study_area.to_crs('EPSG:4326')\n",
    "\n",
    "print(\"✓ All data converted to WGS84\")\n",
    "print(f\"  Edges: {edges_web.crs}\")\n",
    "print(f\"  Nodes: {nodes_web.crs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Nodes Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Preparing nodes data for web application...\\n\")\n",
    "\n",
    "nodes_data = []\n",
    "\n",
    "for idx, node in nodes_web.iterrows():\n",
    "    # Get node ID\n",
    "    node_id = int(idx) if isinstance(idx, (int, np.integer)) else str(idx)\n",
    "    \n",
    "    # Get coordinates\n",
    "    lat = float(node.geometry.y)\n",
    "    lon = float(node.geometry.x)\n",
    "    \n",
    "    nodes_data.append({\n",
    "        'id': node_id,\n",
    "        'lat': lat,\n",
    "        'lon': lon\n",
    "    })\n",
    "\n",
    "print(f\"✓ Prepared {len(nodes_data):,} nodes\")\n",
    "print(f\"\\nSample node:\")\n",
    "print(f\"  {nodes_data[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare Edges Data with Shade Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Preparing edges data with shade scores...\\n\")\n",
    "print(\"This may take a few minutes...\\n\")\n",
    "\n",
    "edges_data = []\n",
    "\n",
    "for idx, edge in edges_web.iterrows():\n",
    "    try:\n",
    "        # Get edge endpoints (u, v, key)\n",
    "        if isinstance(idx, tuple) and len(idx) >= 2:\n",
    "            u, v = idx[0], idx[1]\n",
    "            key = idx[2] if len(idx) > 2 else 0\n",
    "        else:\n",
    "            # Try to get from columns\n",
    "            u = edge.get('u', edge.get('node_start', edge.get('from')))\n",
    "            v = edge.get('v', edge.get('node_end', edge.get('to')))\n",
    "            key = edge.get('key', 0)\n",
    "        \n",
    "        # Convert to appropriate types\n",
    "        u = int(u) if isinstance(u, (int, np.integer)) else str(u)\n",
    "        v = int(v) if isinstance(v, (int, np.integer)) else str(v)\n",
    "        key = int(key)\n",
    "        \n",
    "        # Get geometry coordinates\n",
    "        coords = list(edge.geometry.coords)\n",
    "        coordinates = [[float(lon), float(lat)] for lon, lat in coords]\n",
    "        \n",
    "        # Get edge length\n",
    "        length = float(edge.get('length', 0))\n",
    "        \n",
    "        # Get shade scores for all scenarios\n",
    "        shade_scores = {}\n",
    "        for scenario in scenarios:\n",
    "            col = f'shade_{scenario}'\n",
    "            if col in edge.index or col in edges_web.columns:\n",
    "                shade_val = edge[col]\n",
    "                if pd.notna(shade_val):\n",
    "                    shade_scores[scenario] = float(shade_val)\n",
    "        \n",
    "        # Create edge object\n",
    "        edge_obj = {\n",
    "            'u': u,\n",
    "            'v': v,\n",
    "            'key': key,\n",
    "            'length': length,\n",
    "            'coordinates': coordinates,\n",
    "            'shade': shade_scores\n",
    "        }\n",
    "        \n",
    "        edges_data.append(edge_obj)\n",
    "        \n",
    "        # Progress indicator\n",
    "        if (len(edges_data)) % 2000 == 0:\n",
    "            print(f\"  Processed {len(edges_data):,} / {len(edges_web):,} edges\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"  ⚠ Warning: Could not process edge {idx}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n✓ Prepared {len(edges_data):,} edges with shade scores\")\n",
    "print(f\"\\nSample edge:\")\n",
    "print(json.dumps(edges_data[0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prepare Transit Stops Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Preparing transit stops data...\\n\")\n",
    "\n",
    "stops_data = []\n",
    "\n",
    "for idx, stop in septa_web.iterrows():\n",
    "    stops_data.append({\n",
    "        'name': str(stop.get('stop_name', stop.get('name', 'Transit Stop'))),\n",
    "        'category': str(stop.get('category', 'Transit')),\n",
    "        'lat': float(stop.geometry.y),\n",
    "        'lon': float(stop.geometry.x)\n",
    "    })\n",
    "\n",
    "print(f\"✓ Prepared {len(stops_data)} transit stops\")\n",
    "print(f\"\\nSample stop:\")\n",
    "print(f\"  {stops_data[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Calculate Metadata and Bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculating metadata and bounds...\\n\")\n",
    "\n",
    "# Calculate bounding box\n",
    "all_lats = [n['lat'] for n in nodes_data]\n",
    "all_lons = [n['lon'] for n in nodes_data]\n",
    "\n",
    "bounds = {\n",
    "    'north': float(max(all_lats)),\n",
    "    'south': float(min(all_lats)),\n",
    "    'east': float(max(all_lons)),\n",
    "    'west': float(min(all_lons))\n",
    "}\n",
    "\n",
    "# Calculate center\n",
    "center = {\n",
    "    'lat': (bounds['north'] + bounds['south']) / 2,\n",
    "    'lon': (bounds['east'] + bounds['west']) / 2\n",
    "}\n",
    "\n",
    "# Create metadata\n",
    "metadata = {\n",
    "    'scenarios': scenarios,\n",
    "    'num_nodes': len(nodes_data),\n",
    "    'num_edges': len(edges_data),\n",
    "    'num_stops': len(stops_data),\n",
    "    'bounds': bounds,\n",
    "    'center': center,\n",
    "    'crs': 'EPSG:4326',\n",
    "    'generated': pd.Timestamp.now().isoformat()\n",
    "}\n",
    "\n",
    "print(f\"✓ Metadata created\")\n",
    "print(f\"\\nBounds:\")\n",
    "print(f\"  North: {bounds['north']:.4f}\")\n",
    "print(f\"  South: {bounds['south']:.4f}\")\n",
    "print(f\"  East:  {bounds['east']:.4f}\")\n",
    "print(f\"  West:  {bounds['west']:.4f}\")\n",
    "print(f\"\\nCenter: ({center['lat']:.4f}, {center['lon']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Data Files for Web Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Saving data files for web application...\\n\")\n",
    "\n",
    "# Create output directory\n",
    "output_dir = Path('website/data')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save nodes\n",
    "print(\"1. Saving nodes.json...\")\n",
    "with open(output_dir / 'nodes.json', 'w') as f:\n",
    "    json.dump(nodes_data, f)\n",
    "nodes_size = (output_dir / 'nodes.json').stat().st_size / (1024 * 1024)\n",
    "print(f\"   ✓ Saved: {nodes_size:.2f} MB\")\n",
    "\n",
    "# Save edges\n",
    "print(\"\\n2. Saving edges.json...\")\n",
    "print(\"   (This may take a moment for large networks)\")\n",
    "with open(output_dir / 'edges.json', 'w') as f:\n",
    "    json.dump(edges_data, f)\n",
    "edges_size = (output_dir / 'edges.json').stat().st_size / (1024 * 1024)\n",
    "print(f\"   ✓ Saved: {edges_size:.2f} MB\")\n",
    "\n",
    "# Save stops\n",
    "print(\"\\n3. Saving stops.json...\")\n",
    "with open(output_dir / 'stops.json', 'w') as f:\n",
    "    json.dump(stops_data, f)\n",
    "stops_size = (output_dir / 'stops.json').stat().st_size / (1024 * 1024)\n",
    "print(f\"   ✓ Saved: {stops_size:.2f} MB\")\n",
    "\n",
    "# Save metadata\n",
    "print(\"\\n4. Saving metadata.json...\")\n",
    "with open(output_dir / 'metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "metadata_size = (output_dir / 'metadata.json').stat().st_size / 1024\n",
    "print(f\"   ✓ Saved: {metadata_size:.2f} KB\")\n",
    "\n",
    "print(f\"\\n✓ All files saved to: {output_dir}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Create Compressed Versions (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import shutil\n",
    "\n",
    "print(\"Creating compressed versions for faster loading...\\n\")\n",
    "\n",
    "# Compress large files\n",
    "files_to_compress = ['nodes.json', 'edges.json', 'stops.json']\n",
    "\n",
    "for filename in files_to_compress:\n",
    "    filepath = output_dir / filename\n",
    "    if filepath.exists():\n",
    "        print(f\"Compressing {filename}...\")\n",
    "        \n",
    "        # Read original\n",
    "        with open(filepath, 'rb') as f_in:\n",
    "            # Write compressed\n",
    "            with gzip.open(str(filepath) + '.gz', 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "        \n",
    "        # Check compression ratio\n",
    "        original_size = filepath.stat().st_size / (1024 * 1024)\n",
    "        compressed_size = Path(str(filepath) + '.gz').stat().st_size / (1024 * 1024)\n",
    "        ratio = (1 - compressed_size / original_size) * 100\n",
    "        \n",
    "        print(f\"  Original: {original_size:.2f} MB\")\n",
    "        print(f\"  Compressed: {compressed_size:.2f} MB\")\n",
    "        print(f\"  Savings: {ratio:.1f}%\\n\")\n",
    "\n",
    "print(\"✓ Compressed versions created\")\n",
    "print(\"\\nNote: Web servers can serve .gz files directly with Content-Encoding: gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Validate Output Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validating output data...\\n\")\n",
    "\n",
    "# Load and validate\n",
    "validation_errors = []\n",
    "\n",
    "try:\n",
    "    # Validate nodes\n",
    "    with open(output_dir / 'nodes.json') as f:\n",
    "        nodes_check = json.load(f)\n",
    "    print(f\"✓ nodes.json: {len(nodes_check):,} nodes loaded\")\n",
    "    \n",
    "    # Check node structure\n",
    "    if nodes_check[0].get('id') is None:\n",
    "        validation_errors.append(\"Nodes missing 'id' field\")\n",
    "    if nodes_check[0].get('lat') is None:\n",
    "        validation_errors.append(\"Nodes missing 'lat' field\")\n",
    "    if nodes_check[0].get('lon') is None:\n",
    "        validation_errors.append(\"Nodes missing 'lon' field\")\n",
    "    \n",
    "    # Validate edges\n",
    "    with open(output_dir / 'edges.json') as f:\n",
    "        edges_check = json.load(f)\n",
    "    print(f\"✓ edges.json: {len(edges_check):,} edges loaded\")\n",
    "    \n",
    "    # Check edge structure\n",
    "    if edges_check[0].get('u') is None:\n",
    "        validation_errors.append(\"Edges missing 'u' field\")\n",
    "    if edges_check[0].get('v') is None:\n",
    "        validation_errors.append(\"Edges missing 'v' field\")\n",
    "    if edges_check[0].get('shade') is None:\n",
    "        validation_errors.append(\"Edges missing 'shade' field\")\n",
    "    \n",
    "    # Check shade scenarios\n",
    "    edge_scenarios = list(edges_check[0].get('shade', {}).keys())\n",
    "    print(f\"  Shade scenarios: {len(edge_scenarios)}\")\n",
    "    for s in edge_scenarios[:3]:\n",
    "        print(f\"    • {s}\")\n",
    "    \n",
    "    # Validate stops\n",
    "    with open(output_dir / 'stops.json') as f:\n",
    "        stops_check = json.load(f)\n",
    "    print(f\"✓ stops.json: {len(stops_check)} stops loaded\")\n",
    "    \n",
    "    # Validate metadata\n",
    "    with open(output_dir / 'metadata.json') as f:\n",
    "        metadata_check = json.load(f)\n",
    "    print(f\"✓ metadata.json: {len(metadata_check['scenarios'])} scenarios\")\n",
    "    \n",
    "except Exception as e:\n",
    "    validation_errors.append(f\"File loading error: {str(e)}\")\n",
    "\n",
    "# Report validation\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "if len(validation_errors) == 0:\n",
    "    print(\"VALIDATION PASSED - ALL DATA FILES ARE VALID\")\n",
    "else:\n",
    "    print(\"VALIDATION ISSUES FOUND:\")\n",
    "    for error in validation_errors:\n",
    "        print(f\"  • {error}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"WEB DATA PREPARATION COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nOutput Directory: {output_dir.absolute()}\")\n",
    "print(f\"\\nFiles Created:\")\n",
    "print(f\"  • nodes.json:     {nodes_size:.2f} MB ({len(nodes_data):,} nodes)\")\n",
    "print(f\"  • edges.json:     {edges_size:.2f} MB ({len(edges_data):,} edges)\")\n",
    "print(f\"  • stops.json:     {stops_size:.2f} MB ({len(stops_data)} stops)\")\n",
    "print(f\"  • metadata.json:  {metadata_size:.2f} KB\")\n",
    "print(f\"\\n  Total: {nodes_size + edges_size + stops_size:.2f} MB\")\n",
    "\n",
    "print(f\"\\nData Includes:\")\n",
    "print(f\"  • {len(scenarios)} temporal scenarios\")\n",
    "print(f\"  • Shade scores for all street segments\")\n",
    "print(f\"  • Network structure for routing\")\n",
    "print(f\"  • Transit stop locations\")\n",
    "\n",
    "print(f\"\\nNext Steps:\")\n",
    "print(f\"  1. Copy website/data/ folder to your web hosting\")\n",
    "print(f\"  2. Deploy React application with InteractiveShadeRouting component\")\n",
    "print(f\"  3. Configure web server to serve compressed .gz files\")\n",
    "print(f\"  4. Test routing functionality\")\n",
    "\n",
    "print(f\"\\nPerformance Tips:\")\n",
    "if edges_size > 20:\n",
    "    print(f\"  ⚠ edges.json is {edges_size:.1f} MB - consider:\")\n",
    "    print(f\"    • Using .gz compressed version\")\n",
    "    print(f\"    • Implementing lazy loading\")\n",
    "    print(f\"    • Adding loading progress indicator\")\n",
    "else:\n",
    "    print(f\"  ✓ File sizes are reasonable for web loading\")\n",
    "\n",
    "print(f\"\\nReady for Interactive Web Application!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
